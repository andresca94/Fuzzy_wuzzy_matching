{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1b0c03",
   "metadata": {},
   "source": [
    "## In this exercise, we are going to do a match of two datasets that have information about locations. To solve this problem, we are going to use a Levenshtein distance, using the fuzz ratio function that Python have to compare strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30a0111",
   "metadata": {},
   "source": [
    "### To start, we import the databases and create a conection with MySQL workbench in order to get the info in the RDBMS and make some queries to understan the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07675637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysqlclient in c:\\users\\abril\\anaconda3\\lib\\site-packages (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "## Acá importamos la libreria Pandas y hacemos instalacion de paquete de mysqlclient\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "!pip install mysqlclient\n",
    "\n",
    "# Vamos a Leer los datos desde la ruta donde los tenemos guardados en el pc\n",
    "\n",
    "base_a = pd.read_csv('C:/Users/Abril/PREMISE/prueba_data/base_a.csv')\n",
    "base_b = pd.read_excel('C:/Users/Abril/PREMISE/prueba_data/base_b.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f9c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear conexión a la base de datos MySQL\n",
    "engine = create_engine('mysql://root:toor@localhost:3306/premise')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "588355fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6039"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar en la base de datos\n",
    "base_a.to_sql('base_a', engine, index=False, if_exists='replace')\n",
    "base_b.to_sql('base_b', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e059a8",
   "metadata": {},
   "source": [
    "### Clean and Standardize Data: we switch all the string data in lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "098c531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos \n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Create an engine\n",
    "engine = create_engine('mysql://root:toor@localhost:3306/premise')\n",
    "\n",
    "# Connect to the database\n",
    "connection = engine.connect()\n",
    "\n",
    "# Start a transaction\n",
    "trans = connection.begin()\n",
    "\n",
    "try:\n",
    "    # Run the SQL query for data cleaning and standardization\n",
    "    clean_sql = \"\"\"\n",
    "    UPDATE base_a SET \n",
    "        NombreEstablecimiento = LOWER(NombreEstablecimiento),\n",
    "        NombrePropietario = LOWER(NombrePropietario),\n",
    "        Direccion = LOWER(Direccion),\n",
    "        Ciudad = LOWER(Ciudad);\n",
    "        \n",
    "    UPDATE base_b SET \n",
    "        NombreEstablecimiento = LOWER(NombreEstablecimiento),\n",
    "        NombrePropietario = LOWER(NombrePropietario),\n",
    "        Direccion = LOWER(Direccion),\n",
    "        Ciudad = LOWER(Ciudad);\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query\n",
    "    connection.execute(text(clean_sql))\n",
    "    \n",
    "    # Commit the transaction\n",
    "    trans.commit()\n",
    "    \n",
    "except:\n",
    "    # Rollback the transaction in case of error\n",
    "    trans.rollback()\n",
    "    raise\n",
    "\n",
    "finally:\n",
    "    # Close the connection\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ec31a0",
   "metadata": {},
   "source": [
    "### At this point, we try to create a query for the exact match of the points in the datasets, but we could not find any match, so we have to found a different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c70377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database again\n",
    "connection = engine.connect()\n",
    "\n",
    "# Start a transaction\n",
    "trans = connection.begin()\n",
    "\n",
    "try:\n",
    "    # SQL query for exact matching\n",
    "    exact_match_sql = \"\"\"\n",
    "    CREATE TABLE exact_matches AS\n",
    "    SELECT A.*, B.ID AS ID_from_base_b\n",
    "    FROM base_a A\n",
    "    INNER JOIN base_b B ON \n",
    "        A.NombreEstablecimiento = B.NombreEstablecimiento AND\n",
    "        A.NombrePropietario = B.NombrePropietario AND\n",
    "        A.Direccion = B.Direccion AND\n",
    "        A.Ciudad = B.Ciudad AND\n",
    "        A.GPS = B.GPS;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query\n",
    "    connection.execute(text(exact_match_sql))\n",
    "    \n",
    "    # Commit the transaction\n",
    "    trans.commit()\n",
    "    \n",
    "except Exception as e:\n",
    "    # Rollback the transaction in case of error\n",
    "    trans.rollback()\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    \n",
    "finally:\n",
    "    # Close the connection\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6411b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\abril\\anaconda3\\lib\\site-packages (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abril\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5476c517",
   "metadata": {},
   "source": [
    "### So we try to do the fuzzy match for the attribute \"NombreEstablecimiento\". We got different good matches, but we still have to improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd94ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Connect to the database again\n",
    "connection = engine.connect()\n",
    "\n",
    "# Fetch the data from the database\n",
    "base_a_df = pd.read_sql(\"SELECT * FROM base_a\", connection)\n",
    "base_b_df = pd.read_sql(\"SELECT * FROM base_b\", connection)\n",
    "\n",
    "# Define the fuzzy matching function\n",
    "def fuzzy_match(row):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for _, match_row in base_b_df.iterrows():\n",
    "        score = fuzz.ratio(row['NombreEstablecimiento'], match_row['NombreEstablecimiento'])\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = match_row['ID']\n",
    "            \n",
    "    if best_score >= 85:  # Setting a threshold\n",
    "        return best_match\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Perform fuzzy matching with progress bar\n",
    "base_a_df['ID_from_base_b'] = base_a_df.progress_apply(fuzzy_match, axis=1)\n",
    "\n",
    "# You can save this DataFrame back to a new SQL table or update the existing one, as needed.\n",
    "base_a_df.to_sql('base_a_with_matches', connection, if_exists='replace', index=False)\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb0903",
   "metadata": {},
   "source": [
    "### Data cleanning fot the attribute of the GPS Data in order to be compared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c728d2f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6039"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "tqdm.pandas()\n",
    "\n",
    "# Connect to the database again\n",
    "connection = engine.connect()\n",
    "\n",
    "# Fetch the data from the database\n",
    "base_a_df = pd.read_sql(\"SELECT * FROM base_a\", connection)\n",
    "base_b_df = pd.read_sql(\"SELECT * FROM base_b\", connection)\n",
    "\n",
    "\n",
    "# Function to clean GPS strings\n",
    "def clean_gps_string(gps_str):\n",
    "    if gps_str is None or not isinstance(gps_str, str):\n",
    "        return None  # or return str(gps_str), depending on your needs\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Remove quotes if present\n",
    "        cleaned_str = re.sub(r\"[\\\"']\", \"\", gps_str)\n",
    "        \n",
    "        # Step 2: Replace semicolon with a comma if present\n",
    "        cleaned_str = cleaned_str.replace(\";\", \",\")\n",
    "        \n",
    "        # Step 3: Replace a period that separates the coordinates with a comma\n",
    "        cleaned_str = re.sub(r'(\\-?\\d+\\.\\d+)\\.(\\-?\\d+\\.\\d+)', r'\\1,\\2', cleaned_str)\n",
    "        \n",
    "        # Step 4: If comma appears within a coordinate (which is likely an error), replace it with a period\n",
    "        cleaned_str = re.sub(r'(\\-?\\d+),(\\d+)', r'\\1.\\2', cleaned_str)\n",
    "        \n",
    "        # Step 5: Replace multiple consecutive periods with a single one\n",
    "        cleaned_str = re.sub(r\"\\.{2,}\", \".\", cleaned_str)\n",
    "        \n",
    "        # Check if cleaned_str can be converted to coordinates\n",
    "        x, y = map(float, cleaned_str.split(\",\"))\n",
    "        \n",
    "        return cleaned_str\n",
    "    except ValueError:\n",
    "        return None  # Skip problematic GPS data\n",
    "    \n",
    "    # Clean the GPS coordinates\n",
    "base_a_df['cleaned_GPS'] = base_a_df['GPS'].apply(clean_gps_string)\n",
    "base_b_df['cleaned_GPS'] = base_b_df['GPS'].apply(clean_gps_string)\n",
    "\n",
    "# Update the existing records in MySQL tables\n",
    "base_a_df.to_sql('base_a',connection,if_exists='replace',index=False)\n",
    "base_b_df.to_sql('base_b',connection,if_exists='replace',index=False)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41ceb5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idRegistroEncuesta         int64\n",
       "idEstablecimiento          int64\n",
       "NombreEstablecimiento     object\n",
       "NombrePropietario         object\n",
       "Direccion                 object\n",
       "Ciudad                    object\n",
       "GPS                       object\n",
       "StickerQR                  int64\n",
       "Canal                     object\n",
       "Localidad                  int64\n",
       "SubLocalidad               int64\n",
       "cleaned_GPS               object\n",
       "ID_from_base_b           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_a_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6945356f",
   "metadata": {},
   "source": [
    "### Finally, we do the the fuzzy match with \"NombreEstablecimiento\", \"Ciudad\" and \"direccion\". So we create a function that uses \"fuzz.ratio\" the native function from the library, and weighted the matcht of these three attributtes to get a better assurance. We collect the result on MySQL workbench and we obtain 1601 matches with high quality and just with one repetitive data. This function solve the problem for the matching of two databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb819a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3747/3747 [27:13<00:00,  2.29it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Enhanced fuzzy matching function\n",
    "def enhanced_fuzzy_match(row):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for _, match_row in base_b_df.iterrows():\n",
    "        score1 = fuzz.ratio(row['NombreEstablecimiento'], match_row['NombreEstablecimiento'])\n",
    "        score2 = fuzz.ratio(row['Ciudad'], match_row['Ciudad'])\n",
    "        score3 = fuzz.ratio(row['Direccion'], match_row['Direccion'])\n",
    "        \n",
    "        weighted_score = (score1 + score2 + score3) / 3.0  # Updated the average calculation\n",
    "\n",
    "        if weighted_score > best_score:\n",
    "            best_score = weighted_score\n",
    "            best_match = match_row['ID']\n",
    "            \n",
    "    if best_score >= 85:\n",
    "        return best_match  \n",
    "    return None\n",
    "\n",
    "# Apply the enhanced fuzzy matching function with a progress bar\n",
    "base_a_df['ID_from_base_b'] = base_a_df.progress_apply(enhanced_fuzzy_match, axis=1)\n",
    "# Save the DataFrame back to a new SQL table\n",
    "base_a_df.to_sql('base_a_with_matches', connection, if_exists='replace', index=False)\n",
    "# Close the database connection\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
